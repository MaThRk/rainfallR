---
title: " Extract rainfall data for slopeunit-polygons"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{new_extract_su_rainfall}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
) 
```

# Load the packages

- First we load some of the necessary packages

```{r pkgs, message=F, warning=F}
library(tidyverse) # For much of the data preprocessing
library(rainfallR) # The access and processing of the rainfall data
library(here) # Project paths
library(gganimate) # For a little animation
library(iffitoR) # The landslide data
library(sf) # Handling of the spatial data
library(glue) # Concattening strings
library(purrr) # Mapping functions
library(crayon)  # Coloured consolde output 
library(raster) # Raster data handling
```


# Get the slope units 

- In order to find the slope units on the hard drive in differs between the Linux and the Microsoft path 

```{r}
# which os to automatically set the paths
os = Sys.info()["sysname"]

if(os == "Linux"){
  path_ncdf = "/mnt/CEPH_PROJECTS/Proslide/PREC_GRIDS_updated/"
  su_path = "/mnt/CEPH_PROJECTS/Proslide/Envir_data/SlopeUnits/su_opt_16_TAA/su_16_TAA.shp"
}else if(os == "Windows"){
  path_ncdf = "\\\\projectdata.eurac.edu/projects/Proslide/PREC_GRIDS_updated/"
  su_path = "\\\\projectdata.eurac.edu/projects/Proslide/Envir_data/SlopeUnits/su_opt_16_TAA/su_16_TAA.shp"
}else{
  stop(call. = F, "what the hell are you working on...")
}
```



# What have we got

- Lets understand a bit about the data that we got

- The slope units not only cover South Tyrol, but also the trentino Region. So lets mask it

- We can use the `iffitoR::get_shape_southtyrol`-function in order to get the outline of South Tyrol

```{r plotst, message=F, warning=F}
# get vector of South Tyrol
st = iffitoR::get_shape_southtyrol() 

ggplot(st) +
  geom_sf() +
  theme_minimal()
```


- Now we get the vector data for the slope units

```{r}
su_orig = st_read(su_path)
# and verify directly if they are in the same crs
st_crs(su_orig) == st_crs(st)
```

- As they are not in the same crs, lets reproject the ouline of South Tyrol. The difference, to my knowledge lies in the different geodetic reference systems they use (ETRS89 in the case of South Tyrol and GRS 80 for the slope units).

```{r reprok, warning=F}
st_reproj = st_transform(st,st_crs(su_orig))
st_crs(st_reproj) == st_crs(su_orig)
```


## Clip the slopunits to South Tyrol


- In order to save some computing time we clip the extent of the slope units to the extent of South Tyrol


```{r comparebb}
su = st_crop(su_orig, st_reproj)
# are the two bounding boxes equal?
st_bbox(su) == st_bbox(st_reproj) # for some reason the xmax is not the same
```

- How many slope units are left now?

```{r dimsu}
dim(su_orig) # how many were there
dim(su)
```


# Get the rainfall for the slope Units

- For each Slope Unit we will now get the dates with landslides in them

- We can use the function `slide_dates_in_polygon` in order to extract all the points (landslides-initiation-points) that fall in each polygon (slope unit)

- As we are using the `landsld`-object we are considering landslides of all types. Here is where we should apply some kind of filtering in order to select the slides that are of intereset to us.

- Each polygon (could be catchements, slope units, ...) will have a column in the output that is called `poly_id`. Each observation (each row) is uniquely identifiable by the `date` and the `poly_id`. 

- If there are more than one row for one `poly_id` this means that in the same polygon on several dates slides happened

- We thus only extract the rainfall once for each polygon that saw a movement on a date

- In order to not neglect the fact that potentially multiple slides could have happened, the column `slides_per_poly_date` present the number of slides that happened at that day in that polygon


```{r slidessameday}
su_points_in_poly = rainfallR::slide_dates_in_polygon(poly = su_path
                                                      ,iffi10 = landsld
                                                      ,second_level_regex = NULL
                                                      ,min_year = 2000)
```

- Now we have all the dates of all slides that happened within each polygon of su

- One interesting question would be to ask what the day and slope unit was that saw most movements?


```{r}
su_points_in_poly %>% 
  dplyr::select(c(poly_id, date, month.int, second_level, slides_per_poly_date)) %>%  
  arrange(desc(slides_per_poly_date)) %>% 
  head()
```


# Extract the rainfall data for each su with landslides for each day

- We only are interested in the rainfall of the slope units that actually experienced landslides. Therefore we loop over all the slope units and only take the ones with slides.

> What about the rainfall Events that happened in slope units and did not cause landslides?

- Then we look in the dates column and extract the rainfall for each of the date for that slope unit

- We could do this in sequence


```{r extractinsequence, eval=F}

# make a list for each slope unit that as least had one slide
n_su_with_slides = length(which(su$slide))
su_rainfall = vector("list", length=n_su_with_slides)

# the names of the list are the IDs of the Slope Units
idx = which(su$slide)
ids = su[idx,]$su_id
names(su_rainfall) = ids

# a counter for the print messages
counter = 1
start = Sys.time()
for (row in 1:nrow(su)) {
  
  
  # if there actually happened a slide 
  # this will run as many times as the list elements are in su_rainfall
  
 if (su[row,]$slide) {
   
   n = n_su_with_slides
   str = paste0(counter, "/", n)
   dashes = paste0(replicate(20, "-"), collapse = "")
   cat(yellow$bold$underline("\n------------", str, dashes, "\n\n"))
  
   
   
   # get the current id of the slope unit
   current_id = su[row, ]$su_id
    
   dates = su[row,]$slide_dates[[1]]
    
   ## get the rainfall data for that slope unit the first day
   spatial.obj = su[row, ]
   days_back = 5
   
   # in case a slope unit experienced more than one slide we need an inner list
   inner_su_df = data.frame()
   
   # get the rainfall for each data a landslide happened in that slope unit
   # as we are just getting one date this loop will only run once
   for (day in seq_along(dates)) {
     
     d = dates[[day]]
     
     res = rainfallR::ex_rainfall(data_path = path_ncdf, spatial.obj = spatial.obj, fun = "mean",date = d, days_back = days_back )
     
     # just to make sure you can afterwards identify mulitple slides within one su
     res[["slide_su_id"]] = day
     
     # add the rainfall of that event to the list of all events for that slope unit
     inner_su_df = rbind(inner_su_df, res)
   }
   
   # add this to the outer list 
  su_rainfall[[counter]] = inner_su_list
  
  # increment the counter
  counter = counter + 1
  
 } 
}
end = Sys.time()
took1 = end-start

```


# Lets do it in parallel (with the old function)

```{r extractinparallel, eval=F}

# load the su data with the slide day
su = readRDS(here("local_data/su_with_slide_dates.Rdata"))

library(foreach)
library(doParallel)

# make a list for each slope unit that as least had one slide
n_su_with_slides = length(which(su$slide))
su_rainfall = vector("list", length = n_su_with_slides)

# the names of the list are the IDs of the Slope Units
idx = which(su$slide)
ids = su[idx, ]$su_id
names(su_rainfall) = ids

# a counter for the print messages
counter = 1

# use eight cores
registerDoParallel(6)

start = Sys.time()
output = foreach(
  i = 1:nrow(su),
  .combine = rbind,
  .packages = c("rainfallR",
                "dplyr",
                "magrittr",
                "stringr")
) %dopar% {
  
  # if there actually happened a slide
  
  if (su[i,]$slide) {
    
    # one dataframe for slope units. Possibly multiple days
    df = data.frame()
    
    # get the current id of the slope unit
    current_id = su[i, ]$su_id
    
    # get all the dates in that slope unit
    dates = su[i,]$slide_dates[[1]]
    
    # the spatial object is the slope unit in the for loop
    spatial.obj = su[i, ]
    
    # lets look back 5 days
    days_back = 5
    
    # in case a slope unit experienced more than one slide we need an inner list
    # inner_su_list = vector("list", length = length(dates))
    
    
    # get the rainfall for each data a landslide happened in that slope unit
    # as we are just getting one date this loop will only run once
    for (day in seq_along(dates)) {
      
      # get the day in the slope unit
      d = dates[[day]]
      
      r = rainfallR::ex_rainfall(
        data_path = path_ncdf,
        spatial.obj = spatial.obj,
        fun = "mean",
        date = d,
        days_back = days_back
      )
      
      # just to make sure you can afterwards identify mulitple slides within one su
      r[["su_slide_id"]] = day
      
      # add the rainfall of that event to the list of all events for that slope unit
      # stack up the dataframe for each slope unit
      df = rbind(df, r)
    }
    
    # return the df
    df
  }
}

end = Sys.time()
took2 = end - start
```


# Analyze the results


```{r, eval=F}
# verfiy that each slope unit has one entry for each day
output %>% 
  group_by(su_id, su_slide_id) %>% 
  summarise(n = n()) %>% 
  ungroup() %>% 
  count(n)
```

## look at the antecedent rainfall

```{r, eval=F}
output %>% 
  group_by(su_id, su_slide_id) %>% 
  mutate(unique_id = dplyr::cur_group_id()) %>% 
  ggplot() +
  geom_path(mapping = aes(x = days_before_event,
                  y = cumsum,
                  group = unique_id)) +
  scale_x_reverse() 
  
```


# Use the new `slide_dates_in_polygon`-function

```{r newpointinpolyfuntion}

# rename the data to make it consistent
su = su_points_in_poly

# load the libraries to do parallel processing
library(foreach)
library(doParallel)

# use eight cores
registerDoParallel(6)

# measure the time
start = Sys.time()

res = foreach(
  i = 1:nrow(su),
  .combine = rbind,
  .packages = c("rainfallR",
                "dplyr",
                "magrittr",
                "stringr")
) %dopar% {
    
    # get all the dates in that slope unit
    date = su[i,]$date
    
    # the spatial object is the slope unit in the for loop
    spatial.obj = su[i, ]
    
    # lets look back 5 days
    days_back = 5
    
    r = rainfallR::ex_rainfall(
      data_path = path_ncdf,
      spatial.obj = spatial.obj,
      fun = "mean",
      date = date,
      days_back = days_back
    )
  
    return(r)      
}

end = Sys.time()
took2 = end - start
```











