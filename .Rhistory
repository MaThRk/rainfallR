inner_su_list
day
# get the rainfall for each data a landslide happened in that slope unit
# as we are just getting one date this loop will only run once
for (day in seq_along(dates)) {
d = dates[[day]]
res = rainfallR::get_rainfall(data_path = path_ncdf
,fun = mean
,spatial.obj = spatial.obj
,dts = d
,days_back = days_back)
# again: THIS ALWAYS RETURNS A LIST BUT AS WE ONLY SUPPLY ONE DTS; SELECT THE FIRST ONE
res = rainfallR::make_cumulative_rainfall(res, days_back = days_back) %>% .[[1]]
# add the rainfall of that event to the list of all events for that slides
inner_su_list[[day]] = res
}
# add this to the outer list
su_rainfall[[counter]] = inner_su_list
# increment the counter
counter = counter + 1
for (row in 1:nrow(su)) {
# if there actually happened a slide
# this will run as many times as the list elements are in su_rainfall
if (su[row,]$slide) {
n = n_su_with_slides
str = paste0(counter, "/", n)
dashes = paste0(replicate(20, "-"), collapse = "")
cat(yellow$bold$underline("\n------------", str, dashes, "\n\n"))
# get the current id of the slope unit
current_id = su[row, ]$su_id
dates = su[row,]$slide_dates[[1]]
## get the rainfall data for that slope unit the first day
spatial.obj = su[row, ]
days_back = 5
# in case a slope unit experienced more than one slide on morethan one date we need an inner list
inner_su_list = vector("list", length=length(dates))
# get the rainfall for each data a landslide happened in that slope unit
# as we are just getting one date this loop will only run once
for (day in seq_along(dates)) {
d = dates[[day]]
res = rainfallR::get_rainfall(data_path = path_ncdf
,fun = mean
,spatial.obj = spatial.obj
,dts = d
,days_back = days_back)
# again: THIS ALWAYS RETURNS A LIST BUT AS WE ONLY SUPPLY ONE DTS; SELECT THE FIRST ONE
res = rainfallR::make_cumulative_rainfall(res, days_back = days_back) %>% .[[1]]
# add the rainfall of that event to the list of all events for that slides
inner_su_list[[day]] = res
}
# add this to the outer list
su_rainfall[[counter]] = inner_su_list
# increment the counter
counter = counter + 1
}
}
# make a list for each slope unit that as least had one slide
n_su_with_slides = length = length(which(su$slide))
su_rainfall = vector("list", length=n_su_with_slides)
# the names of the list are the IDs of the Slope Units
idx = which(su$slide)
ids = su[idx,]$su_id
names(su_rainfall) = ids
# a counter for the print messages
counter = 1
for (row in 1:nrow(su)) {
# if there actually happened a slide
# this will run as many times as the list elements are in su_rainfall
if (su[row,]$slide) {
n = n_su_with_slides
str = paste0(counter, "/", n)
dashes = paste0(replicate(20, "-"), collapse = "")
cat(yellow$bold$underline("\n------------", str, dashes, "\n\n"))
# get the current id of the slope unit
current_id = su[row, ]$su_id
dates = su[row,]$slide_dates[[1]]
## get the rainfall data for that slope unit the first day
spatial.obj = su[row, ]
days_back = 5
# in case a slope unit experienced more than one slide on morethan one date we need an inner list
inner_su_list = vector("list", length=length(dates))
# get the rainfall for each data a landslide happened in that slope unit
# as we are just getting one date this loop will only run once
for (day in seq_along(dates)) {
d = dates[[day]]
res = rainfallR::get_rainfall(data_path = path_ncdf
,fun = mean
,spatial.obj = spatial.obj
,dts = d
,days_back = days_back)
# again: THIS ALWAYS RETURNS A LIST BUT AS WE ONLY SUPPLY ONE DTS; SELECT THE FIRST ONE
res = rainfallR::make_cumulative_rainfall(res, days_back = days_back) %>% .[[1]]
# add the rainfall of that event to the list of all events for that slides
inner_su_list[[day]] = res
}
# add this to the outer list
su_rainfall[[counter]] = inner_su_list
# increment the counter
counter = counter + 1
}
}
head(su_rainfall)
class(su_rainfall)
class(su_rainfall[[1]])
class(su_rainfall[[1]][[1]])
# make a list for each slope unit that as least had one slide
n_su_with_slides = length = length(which(su$slide))
su_rainfall = vector("list", length=n_su_with_slides)
# the names of the list are the IDs of the Slope Units
idx = which(su$slide)
ids = su[idx,]$su_id
names(su_rainfall) = ids
# a counter for the print messages
counter = 1
for (row in 1:nrow(su)) {
# if there actually happened a slide
# this will run as many times as the list elements are in su_rainfall
if (su[row,]$slide) {
n = n_su_with_slides
str = paste0(counter, "/", n)
dashes = paste0(replicate(20, "-"), collapse = "")
cat(yellow$bold$underline("\n------------", str, dashes, "\n\n"))
# get the current id of the slope unit
current_id = su[row, ]$su_id
dates = su[row,]$slide_dates[[1]]
## get the rainfall data for that slope unit the first day
spatial.obj = su[row, ]
days_back = 5
# in case a slope unit experienced more than one slide on morethan one date we need an inner list
inner_su_list = vector("list", length=length(dates))
# get the rainfall for each data a landslide happened in that slope unit
# as we are just getting one date this loop will only run once
for (day in seq_along(dates)) {
d = dates[[day]]
res = rainfallR::get_rainfall(data_path = path_ncdf
,fun = mean
,spatial.obj = spatial.obj
,dts = d
,days_back = days_back)
# again: THIS ALWAYS RETURNS A LIST BUT AS WE ONLY SUPPLY ONE DTS; SELECT THE FIRST ONE
res = rainfallR::make_cumulative_rainfall(res, days_back = days_back) %>% .[[1]]
# add the rainfall of that event to the list of all events for that slides
inner_su_list[[day]] = res
}
# add this to the outer list
su_rainfall[[counter]] = inner_su_list
# increment the counter
counter = counter + 1
}
}
class(su_rainfall)
su_rainfall
sapply(su_rainfall, length)
a = sapply(su_rainfall, length)
which(a > 1)
su_rainfall[[[9]]]
su_rainfall[[9]]
a = su_rainfall[[9]]
class(a)
a[[1]]
class(a[[1]])
bind_rows(a)
a
b = su_rainfall[[1]]
b
class(b)
# bind each inner list of dataframes into one dataframe
one_df_each_su = lapply(su_rainfall, bind_rows)
length(one_df_each_su)
one_df_each_su[[1]]
one_df_each_su[[2]]
# now create one big dataframe
one_df_all_su = bind_rows(one_df_each_su)
dim(one_df_all_su)
head(one_df_all_su)
ggplot(one_df_all_su) %>%
geom_path(aes(x=days_before_event, y=cumsum, group=su_id))
ggplot(one_df_all_su) +
geom_path(aes(x=days_before_event, y=cumsum, group=su_id))
ggplot(one_df_all_su) +
geom_path(aes(x=days_before_event, y=cumsum, group=su_id)) +
scale_x_reverse()
ggplot(one_df_all_su) +
geom_path(aes(x=days_before_event, y=cumsum, group=su_id)) +
scale_x_reverse() +
theme_void()
mapping = aes(x=days_before_event, y=cumsum, group=su_id),
ggplot(one_df_all_su) +
geom_path(
mapping = aes(x=days_before_event, y=cumsum, group=su_id),
alpha=.2) +
scale_x_reverse() +
theme_void()
library(gganimate)
ggplot(one_df_all_su) +
geom_path(
mapping = aes(x=days_before_event, y=cumsum, group=su_id),
alpha=.2) +
scale_x_reverse() +
theme_void() +
transition_reveal(days_before_event)
one_df_all_su %>%
group_by(su_id) %>%
mutate(time_anim = row_numer())
one_df_all_su %>%
group_by(su_id) %>%
mutate(time_anim = row_number())
one_df_all_su %>%
group_by(su_id) %>%
mutate(time_anim = row_number()) %>% head(9)
one_df_all_su %>%
group_by(su_id) %>%
mutate(time_anim = row_number()) %>%
ggplot() +
geom_path(mapping = aes(x = days_before_event, y = cumsum, group = su_id),
alpha = .2) +
scale_x_reverse() +
theme_void() +
transition_reveal(days_before_event)
one_df_all_su %>%
group_by(su_id) %>%
mutate(time_anim = row_number()) %>%
ggplot() +
geom_path(mapping = aes(x = days_before_event, y = cumsum, group = su_id),
alpha = .2) +
scale_x_reverse() +
theme_void() +
transition_time(time_anim)
install.packages("transformer")
install.packages("transformr")
library(transformr)
one_df_all_su %>%
group_by(su_id) %>%
mutate(time_anim = row_number()) %>%
ggplot() +
geom_path(mapping = aes(x = days_before_event, y = cumsum, group = su_id),
alpha = .2) +
scale_x_reverse() +
theme_void() +
transition_time(time_anim)
one_df_all_su %>%
group_by(su_id) %>%
mutate(time_anim = row_number()) %>%
ggplot() +
geom_path(mapping = aes(x = days_before_event, y = cumsum, group = su_id),
alpha = .2) +
scale_x_reverse() +
theme_void() +
transition_reveal(time_anim)
one_df_all_su %>%
group_by(su_id) %>%
mutate(time_anim = row_number()) %>%
ggplot() +
geom_path(mapping = aes(x = days_before_event, y = cumsum, group = su_id),
alpha = .2) +
scale_x_reverse() +
theme_minimal() +
transition_reveal(time_anim)
one_df_all_su %>%
slice(1:50)
one_df_all_su %>%
slice(1:50) %>%
group_by(su_id) %>%
mutate(time_anim = row_number()) %>%
ggplot() +
geom_path(mapping = aes(x = days_before_event, y = cumsum, group = su_id),
alpha = .2) +
scale_x_reverse() +
theme_minimal() +
transition_reveal(time_anim)
one_df_all_su %>%
slice(1:50) %>%
group_by(su_id) %>%
mutate(time_anim = row_number()) %>%
ggplot() +
geom_path(mapping = aes(x = days_before_event, y = cumsum, group = su_id),
alpha = .2) +
geom_point(aes(x=days_before_event, y=cumsum, group=su_id)) +
scale_x_reverse() +
theme_minimal() +
transition_reveal(time_anim)
one_df_all_su %>%
slice(1:180) %>%
group_by(su_id) %>%
mutate(time_anim = row_number()) %>%
ggplot() +
geom_path(mapping = aes(x = days_before_event, y = cumsum, group = su_id),
alpha = .2) +
geom_point(aes(x=days_before_event, y=cumsum, group=su_id)) +
scale_x_reverse() +
theme_minimal() +
transition_reveal(time_anim)
a = one_df_all_su %>%
slice(1:180) %>%
group_by(su_id) %>%
mutate(time_anim = row_number())
a
a %>% count(time_anim)
a
a %>% count(time_anim, sort=T)
a %>% group_by(time_anim) %>% summarise(each = sum(n))
a %>% group_by(time_anim) %>% summarise(each = sum(time_anim))
unique(time_anim)
unique(one_df_all$time_anim)
unique(one_df_all$time_anim)
a = one_df_all_su %>%
slice(1:180) %>%
group_by(su_id) %>%
mutate(time_anim = row_number())
unique(a$time_anim)
a %>% filter(time_anim == 12)
a %>% filter(time_anim > 6)
View(a)
a = one_df_all_su %>%
slice(1:180) %>%
group_by(su_id, date_consid) %>%
mutate(time_anim = row_number())
View(a)
dim(a)
row = 923
su[row,]$slide
# get the current id of the slope unit
current_id = su[row, ]$su_id
dates = su[row,]$slide_dates[[1]]
daets
daets
dates
row
# get the original id from the slope units
id_su = su[row, ][["su_id"]]
id_su
# select all the possible (minimum 1) rows from the joined table
joined_selected = joined %>%
filter(su_id == id_su)
joined_selected
joined_selected
# get the translational slides
slides = landsld %>%
filter(str_detect(second_level, "translational")) %>%
filter(date_info == "day") %>%
filter(year.int >= 1980) %>%
mutate(.id = 1:nrow(.)) %>% # give each slide a unique id
st_transform(st_crs(su))
slides
# assign each slope unit an id
su$su_id = 1:nrow(su)
# apply spatial join
# this can have more rows than the original su dataframe
# each su will appear that many times as they have points in them
joined = st_join(su, slides)
# how many slides per points
slides_per_poly =  joined %>%
count(su_id, sort = T)
row
# get the original id from the slope units
id_su = su[row, ][["su_id"]]
# select all the possible (minimum 1) rows from the joined table
joined_selected = joined %>%
filter(su_id == id_su)
joined_selected
?dplyr::distinct
# we only want the the rainfall per Slop Unit. And are not directly interested in the single landslides polygons. So if
# there are more than one landslide in one su on the same day, we only take one
joined_selected = joined_selected %>% dplyr::distinct(PIFF_ID, .keep_all=T)
joined_selected
# we only want the the rainfall per Slop Unit. And are not directly interested in the single landslides polygons. So if
# there are more than one landslide in one su on the same day, we only take one
joined_selected = joined_selected %>% dplyr::distinct(date, .keep_all=T)
joined_selected
# assign to each su true or false value if it has or has no landslides
for (row in 1:nrow(su)) {
# get the original id from the slope units
id_su = su[row, ][["su_id"]]
# select all the possible (minimum 1) rows from the joined table
joined_selected = joined %>%
filter(su_id == id_su)
# we only want the the rainfall per Slop Unit. And are not directly interested in the single landslides polygons. So if
# there are more than one landslide in one su on the same day, we only take one
joined_selected = joined_selected %>% dplyr::distinct(date, .keep_all=T)
# check if the slope unit in the joined table has a value in the .id column from the points
slide_dates_per_su = rep(NA, nrow(joined_selected))
# check how many points fall in the slope unit for the seleted id
for (point in 1:nrow(joined_selected)) {
# if there is a value in the .id-column (so there is a point), get the
if (!is.na(joined_selected[point, ]$.id)) {
date = joined_selected[point, ]$date
slide_dates_per_su[[point]] = date
}
}
# convert back to datetime object
slide_dates_per_su = as.Date.numeric(slide_dates_per_su, origin="1970-01-01")
su$slide_dates[[row]] = slide_dates_per_su
}
# make the binary classification
su = su %>%
mutate(
slide = if_else(!is.na(slide_dates), TRUE, FALSE)
)
# make a list for each slope unit that as least had one slide
n_su_with_slides = length = length(which(su$slide))
su_rainfall = vector("list", length=n_su_with_slides)
# the names of the list are the IDs of the Slope Units
idx = which(su$slide)
ids = su[idx,]$su_id
names(su_rainfall) = ids
# a counter for the print messages
counter = 1
for (row in 1:nrow(su)) {
# if there actually happened a slide
# this will run as many times as the list elements are in su_rainfall
if (su[row,]$slide) {
n = n_su_with_slides
str = paste0(counter, "/", n)
dashes = paste0(replicate(20, "-"), collapse = "")
cat(yellow$bold$underline("\n------------", str, dashes, "\n\n"))
# get the current id of the slope unit
current_id = su[row, ]$su_id
dates = su[row,]$slide_dates[[1]]
## get the rainfall data for that slope unit the first day
spatial.obj = su[row, ]
days_back = 5
# in case a slope unit experienced more than one slide on morethan one date we need an inner list
inner_su_list = vector("list", length=length(dates))
# get the rainfall for each data a landslide happened in that slope unit
# as we are just getting one date this loop will only run once
for (day in seq_along(dates)) {
d = dates[[day]]
res = rainfallR::get_rainfall(data_path = path_ncdf
,fun = mean
,spatial.obj = spatial.obj
,dts = d
,days_back = days_back)
# again: THIS ALWAYS RETURNS A LIST BUT AS WE ONLY SUPPLY ONE DTS; SELECT THE FIRST ONE
res = rainfallR::make_cumulative_rainfall(res, days_back = days_back) %>% .[[1]]
# add the rainfall of that event to the list of all events for that slides
inner_su_list[[day]] = res
}
# add this to the outer list
su_rainfall[[counter]] = inner_su_list
# increment the counter
counter = counter + 1
}
}
one_df_all_su %>%
slice(1:180) %>%
group_by(su_id, date_consid) %>%
mutate(time_anim = row_number()) %>%
ggplot() +
geom_path(mapping = aes(x = days_before_event, y = cumsum, group = su_id),
alpha = .2) +
geom_point(aes(x=days_before_event, y=cumsum, group=su_id)) +
scale_x_reverse() +
theme_minimal() +
transition_reveal(time_anim)
unique(one_df_all_su$su_id)
count(one_df_all_su$su_id)
count(one_df_all_su, su_id)
# now create one big dataframe
one_df_all_su = bind_rows(one_df_each_su)
one_df_all_su
one_df_all_su %>% group_by(su_id) %>% summarise(n = n())
res = one_df_all_su %>% group_by(su_id) %>% summarise(n = n())
unique(res$n)
row = 378
# get the current id of the slope unit
current_id = su[row, ]$su_id
current_id
dates = su[row,]$slide_dates[[1]]
dates
## get the rainfall data for that slope unit the first day
spatial.obj = su[row, ]
days_back = 5
# in case a slope unit experienced more than one slide on morethan one date we need an inner list
inner_su_list = vector("list", length=length(dates))
a = one_df_all_su %>%
group_by(su_id, date_consid)
dim8a
dim8a
dim(a)
a
a = one_df_all_su %>%
group_by(su_id, date_consid) %>%
summarise(n = n())
a
unique(a$n)
filter(a, n > 6)
row = 923
# get the original id from the slope units
id_su = su[row, ][["su_id"]]
id_su
# select all the possible (minimum 1) rows from the joined table
joined_selected = joined %>%
filter(su_id == id_su)
# we only want the the rainfall per Slop Unit. And are not directly interested in the single landslides polygons. So if
# there are more than one landslide in one su on the same day, we only take one
joined_selected = joined_selected %>% dplyr::distinct(date, .keep_all=T)
joined_selected
# check if the slope unit in the joined table has a value in the .id column from the points
slide_dates_per_su = rep(NA, nrow(joined_selected))
slide_dates_per_su
# check how many points fall in the slope unit for the seleted id
for (point in 1:nrow(joined_selected)) {
# if there is a value in the .id-column (so there is a point), get the
if (!is.na(joined_selected[point, ]$.id)) {
date = joined_selected[point, ]$date
slide_dates_per_su[[point]] = date
}
}
slide_dates_per_su
# convert back to datetime object
slide_dates_per_su = as.Date.numeric(slide_dates_per_su, origin="1970-01-01")
slide_dates_per_su
